{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardAlba/UdAAnaliticaFinancera/blob/main/UdAS%26P500_Data_Loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVDsHcizCamw",
        "outputId": "7d1ee356-aef2-4484-fc7e-fd7aca4cc0aa"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.41)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfhzeQLV0J0o"
      },
      "source": [
        "try:\n",
        "    import yfinance as yf\n",
        "except ImportError:\n",
        "    raise ImportError(\"Cannot start without 'yfinance' package.\\nInstall it before running the code again.\")\n",
        "\n",
        "import bs4 as bs\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "\n",
        "class SP500DataLoader:\n",
        "    def __init__(self):\n",
        "        if not os.path.exists('Data'):\n",
        "            os.makedirs('Data')\n",
        "\n",
        "        self.start_date, self.end_date = None, None\n",
        "        self.cleaned_prices = None\n",
        "        self.cleaned_returns = None\n",
        "        self.raw_prices = None\n",
        "        self.raw_returns = None\n",
        "\n",
        "        # Download stocks names from S&P500 page on wikipedia\n",
        "        resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "        soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
        "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "        self.tickers = []\n",
        "        for row in table.findAll('tr')[1:]:\n",
        "            ticker = row.findAll('td')[0].text\n",
        "            self.tickers.append(ticker)\n",
        "        self.tickers = [s.replace('\\n', '') for s in self.tickers]\n",
        "        self.tickers = self.tickers + [\"SPY\"]\n",
        "\n",
        "    # Check whether 'start_date' and 'end_date' make a valid date range or not\n",
        "    def check_date_range(self, start_date: tuple, end_date: tuple):\n",
        "        start = datetime(*start_date)\n",
        "        end = datetime(*end_date)\n",
        "\n",
        "        if end <= start:\n",
        "            raise Exception(\"The start date must be before the end date!\")\n",
        "\n",
        "        return start, end\n",
        "\n",
        "    # Doanload prices using yfinance\n",
        "    def download_prices(self, start_date, end_date, interval='1d', column='Adj Close'):\n",
        "        self.start_date, self.end_date = self.check_date_range(start_date, end_date)\n",
        "        self.raw_prices = yf.download(self.tickers, start=self.start_date, end=self.end_date, interval=interval)[column]\n",
        "\n",
        "    # Helper function to write dataframes on files with specified names\n",
        "    def write_on_disk(self, data: DataFrame, filename: str):\n",
        "        if \"csv\" in filename:\n",
        "            data.to_csv('Data/' + filename)\n",
        "        elif \"h5\" in filename:\n",
        "            data.to_hdf('Data/' + filename, 'fixed', mode='w', complib='blosc', complevel=9)\n",
        "\n",
        "        print(f\"Saved: Data/{filename}\")\n",
        "\n",
        "    # Return a list of stock names in S&P 500 index\n",
        "    def get_stocks_list(self):\n",
        "        return self.tickers.copy()\n",
        "\n",
        "    # Return raw prices data (which is not cleaned)\n",
        "    def get_raw_prices(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
        "        self.download_prices(start_date, end_date)\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.h5\")\n",
        "\n",
        "        return self.raw_prices\n",
        "\n",
        "    # Calculate and return raw returns data (which is not cleaned)\n",
        "    def get_raw_returns(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
        "        self.get_raw_prices(start_date, end_date)\n",
        "\n",
        "        self.raw_returns = self.raw_prices.copy()\n",
        "        self.raw_returns = np.log(self.raw_returns).diff()\n",
        "        self.raw_returns = self.raw_returns.iloc[1:]  # removes first row which is NaN after diff()\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.h5\")\n",
        "\n",
        "        return self.raw_returns\n",
        "\n",
        "    # Return cleaned prices data (stocks with at least on NAN value are excluded)\n",
        "    def get_cleaned_prices(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
        "        self.get_raw_prices(start_date, end_date)\n",
        "\n",
        "        self.cleaned_prices = self.raw_prices.copy()\n",
        "        # Remove companies (columns) with all missing values for whole time range\n",
        "        self.cleaned_prices.dropna(axis='columns', how='all', inplace=True)\n",
        "        # Remove days (rows) with missing values for all of companies\n",
        "        self.cleaned_prices.dropna(axis='index', how='all', inplace=True)\n",
        "        # Finally, remove the columns with at least one Nan (missing value)\n",
        "        self.cleaned_prices.dropna(axis='columns', how='any', inplace=True)\n",
        "\n",
        "        if save_as_csv:\n",
        "            #En el repositori original, hi havia error: self.self.mÃ¨tode\n",
        "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.h5\")\n",
        "\n",
        "        return self.cleaned_prices\n",
        "\n",
        "    # Calculate return values using cleaned data, and return the dataframe\n",
        "    def get_cleaned_returns(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
        "        self.get_cleaned_prices(start_date, end_date)\n",
        "\n",
        "        self.cleaned_returns = self.cleaned_prices.copy()\n",
        "        self.cleaned_returns = np.log(self.cleaned_returns).diff()\n",
        "        self.cleaned_returns = self.cleaned_returns.iloc[1:]  # removes first row which is NaN after diff()\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.h5\")\n",
        "\n",
        "        return self.cleaned_returns\n",
        "\n",
        "    # Return the last values for raw prices without redownloading them\n",
        "    def get_last_raw_prices(self, save_as_h5=False, save_as_csv=False):\n",
        "        if self.raw_prices is None:\n",
        "            return None\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.h5\")\n",
        "\n",
        "        return self.raw_prices\n",
        "\n",
        "    # Return the last values for raw returns without redownloading them\n",
        "    def get_last_raw_returns(self, save_as_h5=False, save_as_csv=False):\n",
        "        if self.raw_returns is None:\n",
        "            return None\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.h5\")\n",
        "\n",
        "        return self.raw_returns\n",
        "\n",
        "    # Return the last values for cleaned prices without redownloading them\n",
        "    def get_last_cleaned_prices(self, save_as_h5=False, save_as_csv=False):\n",
        "        if self.cleaned_prices is None:\n",
        "            return None\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.h5\")\n",
        "\n",
        "        return self.cleaned_prices\n",
        "\n",
        "    # Return the last values for cleaned returns without redownloading them\n",
        "    def get_last_cleaned_returns(self, save_as_h5=False, save_as_csv=False):\n",
        "        if self.cleaned_returns is None:\n",
        "            return None\n",
        "\n",
        "        if save_as_csv:\n",
        "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.csv\")\n",
        "        if save_as_h5:\n",
        "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.h5\")\n",
        "\n",
        "        return self.cleaned_returns\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMM95YYPno_z",
        "outputId": "7784a7bc-ae7e-41ae-8586-f1fa5f7c0deb"
      },
      "source": [
        "# TEST\n",
        "# Driver code for testing purpose\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_downloader_object = SP500DataLoader()\n",
        "\n",
        "    # Get cleaned return values\n",
        "    #cleaned_returns = data_downloader_object.get_cleaned_returns(\n",
        "    #    start_date=(2020, 1, 1), end_date=(2020, 12, 30),\n",
        "    #    interval='1d', column='Adj Close',\n",
        "    #    save_as_h5=True, save_as_csv=True\n",
        "    #)\n",
        "\n",
        "    #Provem amb preus\n",
        "    cleaned_prices = data_downloader_object.get_cleaned_prices(\n",
        "        start_date=(2020, 1, 1), end_date=(2024, 7, 31),\n",
        "        interval='1d', column='Adj Close',\n",
        "        save_as_h5=True, save_as_csv=True\n",
        "    )\n",
        "\n",
        "    # Print a part of the dataframe of cleaned returns\n",
        "    print(\"--------------------------------------------\")\n",
        "    #print(cleaned_prices.head(10))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[**********************78%%***********           ]  395 of 504 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$BF.B: possibly delisted; No price data found  (1d 2020-01-01 00:00:00 -> 2024-07-31 00:00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  504 of 504 completed\n",
            "ERROR:yfinance:\n",
            "2 Failed downloads:\n",
            "ERROR:yfinance:['BRK.B']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
            "ERROR:yfinance:['BF.B']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2020-01-01 00:00:00 -> 2024-07-31 00:00:00)')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: Data/S&P500-cleaned_prices.csv\n",
            "Saved: Data/S&P500-cleaned_prices.h5\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}